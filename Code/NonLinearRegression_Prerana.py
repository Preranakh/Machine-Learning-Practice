# -*- coding: utf-8 -*-
"""Non_Linear Khatiwada.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1hGGuqSMY4lwX8krIwV8xuUDeRUyGejNx
"""

import numpy as np
from matplotlib import pyplot as plt
np.random.seed(0)
n=10
m=8
x_train = np.linspace(0,3,n)
y_train = -x_train**2 +2*x_train + 2 +0.5*np.random.randn(n)
#print(x_train.shape,y_train.shape)
x_test = np.linspace(0,3,m)
y_test = -x_test**2 +2*x_test + 2 + 0.5*np.random.randn(m)
#print(x_test.shape,y_test.shape)
plt.plot(x_train,y_train,'o')
plt.plot(x_test,y_test,'x')
plt.legend(['training samples','test samples','true line'])

def linearPoly(y_list,phi_x,lambda22,n):
  phi_means=np.zeros((1,4))
  phi_means = [phi_x.mean(axis=0)]

  Y_mean=np.mean(y_list)
  phi_means=np.array(phi_means)

  phi_tild=np.subtract(phi_x,phi_means)

  phi_tild_trans=phi_tild.T

  y_tild=np.subtract(y_list,Y_mean)

  phi_product=np.dot(phi_tild_trans,phi_tild)

  Identity_Matrix=np.identity(4)

  nLambda=n*np.multiply(Identity_Matrix,lambda22)

  w=phi_product+nLambda

  phi_total_inv=np.linalg.inv(w)
#print(phi_total_inv)
  phi_T_y=np.dot(phi_tild_trans,y_tild)
#print(phi_T_y.shape)
  W_hat=np.dot(phi_total_inv,phi_T_y)
#print(W_hat.shape)
#print(W_hat)
  w_hat_trans=W_hat.T
#print(w_hat_trans.shape)
  w_phiT_product=np.dot(W_hat.T,phi_means.T)
  b_hat=Y_mean-w_phiT_product
  return W_hat, b_hat
#print(b_hat.shape)

def predict_error(y_train,W_hat,B,X_array1,n):
  Ypredict=np.zeros((n,1))
  sum=0
  for i in range(n):
    sum=0
    for j in range(4):
      sum=sum+np.dot(W_hat[j],X_array1[i][j])
    sum=sum+B
    Ypredict[i]=sum
 # print(Ypredict.shape)
  sum1=0
  for i in range(n):
    p=Ypredict[i]-y_train[i]
    p=pow(p,2)
    sum1=sum1+p
  mean_square= sum1/n
 # print("mean square error", mean_square)
  return Ypredict,mean_square

############ NUMBER 3 A ####################################
l = 0.01##learning rate defined
phi_x=[]

for i in x_train:
  x_temp=[]
  x_temp.append(i**1)
  x_temp.append(i**2)
  x_temp.append(i**3)
  x_temp.append(i**4)
  phi_x.append(x_temp)
phi_x=np.array(phi_x)
print(phi_x.shape)
y_list=[]
x_list1=[]
for i in y_train:
  y_list.append([i])
y_list=np.array(y_list)
print(y_list.shape)
for i in x_train:
  x_list1.append([i])
x_list1=np.array(x_list1)

lambda22=0.1
W_hat,b_hat=linearPoly(y_list,phi_x,lambda22,n)
print(W_hat,b_hat)

phi_xTest=[]

for i in x_test:
  x_temp1=[]
  x_temp1.append(i**1)
  x_temp1.append(i**2)
  x_temp1.append(i**3)
  x_temp1.append(i**4)
  phi_xTest.append(x_temp1)
phi_xTest=np.array(phi_xTest)
print(phi_xTest.shape)
y_list_test=[]

for i in y_test:
  y_list_test.append([i])
y_list_test=np.array(y_list_test)
print(y_list_test.shape)

i=0
plt_t=[]
plt_test=[]
lambdaX=[]
lambda1=0.001
m=8

while lambda1<=0.1:
  #### training error########
  lambdaX.append(lambda1)
  W_hat,B=linearPoly(y_list,phi_x,lambda1,n)
 # print("Question 3 a. W=\n",W_hat,"B=",B)
  Ypredict,meanTrain=predict_error(y_train,W_hat,B,phi_x,n)
  plt_t.append(meanTrain)
  YpredictTest,meanTest=predict_error(y_test,W_hat,B,phi_xTest,m)
  plt_test.append(meanTest)
  print("For lambda = ",lambda1, "\nmean square value for training set = ", meanTrain, "\nmean square value for test set = ", meanTest, )
  lambda1=lambda1+0.001
  i=i+1
plt_t=np.array(plt_t)
#plt.figure(figsize=(200,400))
print("number of iteration",i)

x = np.copy(lambdaX)
y = np.copy(plt_t)
plt.figure(figsize=(20,4))
plt.xticks(np.arange(min(x), max(x)+0.1, 0.001))
plt.xticks(rotation = 90)
plt.plot(x,y)
plt.show()

x = np.copy(lambdaX)
y = np.copy(plt_test)
plt.figure(figsize=(20,4))
plt.xticks(np.arange(min(x), max(x)+0.1, 0.001))
plt.xticks(rotation = 90)
plt.plot(x,y)
plt.show()