# -*- coding: utf-8 -*-
"""ProjectPaper2018.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xB1xkbQZvUBPdxsBQXGxTXKrmejBMAHP
"""

from google.colab import drive
drive.mount('/content/drive')

cd drive/MyDrive/Colab\ Notebooks/

!unrar x KTH.rar /content

import tensorflow as tf
tf.test.gpu_device_name()

!pip install keras-video-generators

import os
import glob
import keras
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import TimeDistributed, GRU, Dense, Flatten, Dropout, LSTM
from tensorflow.keras.optimizers import SGD, Adam, RMSprop
from tensorflow.keras.callbacks import ModelCheckpoint

from keras.layers import Conv2D, BatchNormalization, MaxPool2D, GlobalMaxPool2D, Activation
from keras.models import Sequential
from keras.layers import TimeDistributed, GRU, Dense, Flatten, Dropout

from keras_video import VideoFrameGenerator

glob_pattern='/content/KTH/{classname}/*.avi' 
print(glob_pattern)

for i in glob.glob('/content/KTH/*'):
  print(i)

classes = [i.split('/')[3] for i in glob.glob('/content/KTH/*')]
classes.sort()

print(classes)

SIZE = (128, 128)
CHANNELS = 3
NBFRAME = 13 #13,8
BS = 1

#from keras.applications.vgg16 import preprocess_input
#train_glob_pattern='dataset/train/{classname}/*.avi'
#valid_glob_pattern='dataset/test/{classname}/*.avi'

train_data_aug = keras.preprocessing.image.ImageDataGenerator(
        rescale = 1./255,
    )

train = VideoFrameGenerator(
    classes=classes, 
    glob_pattern=glob_pattern,
    nb_frames=NBFRAME,
    shuffle=True,
    batch_size=BS,
    split=.20,
    target_shape=SIZE,
    nb_channel=CHANNELS,
    transformation=train_data_aug,
    use_frame_cache=True)

#valid_data_aug = keras.preprocessing.image.ImageDataGenerator(
 #       rescale = 1./255
   # )
valid= train.get_validation_generator()

# valid = VideoFrameGenerator(
#     classes=classes, 
#     glob_pattern=glob_pattern,
#     nb_frames=NBFRAME,
#     shuffle=True,
#     batch_size=BS,
#     target_shape=SIZE,
#     nb_channel=CHANNELS,
#     transformation=valid_data_aug,
#     use_frame_cache=True)

def build_convnet(shape=(128, 128, 3)):
    model = Sequential()
    model.add(Conv2D(32, (3,3), input_shape=shape))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
    model.add(MaxPool2D(pool_size=(2, 2), strides=2))
    
    model.add(Conv2D(128, (3,3),  dilation_rate=(1, 2), padding='same'))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
    
    model.add(Conv2D(128, (3,3),  dilation_rate=(2, 1), padding='same'))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
     
    model.add(Conv2D(128, (3,3),  dilation_rate=(2, 2), padding='same'))
    model.add(Activation('relu'))
    model.add(BatchNormalization())
    

    model.summary()
    return model

def action_model(shape=(13, 128, 128, 3), nbout=15):
    convnet = build_convnet(shape[1:])
    model = Sequential()    
    model.add(TimeDistributed(convnet, input_shape=shape))
    model.add(TimeDistributed(Dense(64, activation='relu')))
    model.add(TimeDistributed(Flatten()))
    model.add(GRU(64, dropout=0.2)) 
    # # model.add(Dropout(.10))
    model.add(Dense(nbout, activation='softmax'))
    # model.summary()
    return model

INSHAPE=(NBFRAME,) + SIZE + (CHANNELS,) # (10, 150, 150, 3)
model = action_model(INSHAPE, len(classes))
model.summary()

optimizer = RMSprop(lr=1e-4)
model.compile(
    optimizer=optimizer,
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

EPOCHS=45
callbacks = [
    ModelCheckpoint('/content/drive/MyDrive/Colab Notebooks/kth.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)
]

history = model.fit_generator(
    train,
    steps_per_epoch = len(train) // BS,
    validation_data=valid,
    validation_steps = len(valid), 
    verbose=1,
    epochs=EPOCHS,
    callbacks=callbacks
)

y_labels = []
y_labels_array = []
batch = 0
y_true = []
y_preds = []
i = 0

import numpy as np

for x,y in valid:
    if batch == 119:
       break
    batch += 1
    
    label = np.argmax(y, axis=1)
    y_labels.append(label)
    
    Y_pred = model.predict(x)
    y_pred = np.argmax(Y_pred, axis=1)
    y_preds.append(y_pred)

print (Y_pred.shape, len(y_labels))

from sklearn.metrics import classification_report, confusion_matrix
print('Confusion Matrix')
conf_mat=confusion_matrix(y_labels, y_preds)
print(conf_mat)
print('Classification Report')
classes =  ['boxing', 'Handclapping', 'Handwaving', 'Jogging', 'Running', 'Walking']
print(classification_report(y_labels, y_preds, target_names=classes))
report = classification_report(y_labels, y_preds, target_names=classes, output_dict=True)
accuracy = report['accuracy']

import itertools
import matplotlib.pyplot as plt
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',size = 15,
                          cmap=plt.cm.YlGnBu):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    # plt.figure(figsize=(8, 10)) # for 22 class
    plt.figure(figsize=(6,6))
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    # plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=70)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j], weight='bold', fontsize=16,
                 horizontalalignment="center", va="center",
                 color="white" if cm[i, j] > thresh else "black")

    # plt.tight_layout()
#    plt.tight_layout(pad=0.2, w_pad=0.8, h_pad=0.6)
    # plt.xlim(-0.1, -0.5)
   # plt.ylim(-0.50, 11.50) # for 22 classes
    # plt.xlim(-0.40, 9.5)
    # plt.ylim(-0.40, 9.50)
    plt.ylabel('True label',size = 15)
    plt.xlabel('Predicted label',size = 15)
    
target_names =  ['Boxing', 'Handclapping', 'Handwaving', 'Jogging', 'Running', 'Walking']
plot_confusion_matrix(conf_mat, classes=target_names,
                      title='Confusion matrix',size = 15)
plt.tight_layout(pad=0.2, w_pad=0.8, h_pad=0.6)
plt.show()

plt.figure(figsize=(7,6))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.figure(figsize=(7,6))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()